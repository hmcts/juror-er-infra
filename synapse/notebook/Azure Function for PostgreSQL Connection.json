{
	"name": "Azure Function for PostgreSQL Connection",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sparkstg",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "96f5f892-806c-46b3-8648-3d842f92d0da"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/74dacd4f-a248-45bb-a2f0-af700dc4cf68/resourceGroups/baubais-data-factory-rg-stg/providers/Microsoft.Synapse/workspaces/baubais-synapse-stg/bigDataPools/sparkstg",
				"name": "sparkstg",
				"type": "Spark",
				"endpoint": "https://baubais-synapse-stg.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkstg",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import logging\n",
					"import azure.functions as func\n",
					"import psycopg2\n",
					"import json\n",
					"import os\n",
					"from psycopg2.extras import execute_batch"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# Get connection details from environment variables for security\n",
					"DB_HOST = os.environ[\"DB_HOST\"]\n",
					"DB_NAME = os.environ[\"DB_NAME\"]\n",
					"DB_USER = os.environ[\"DB_USER\"]\n",
					"DB_PASSWORD = os.environ[\"DB_PASSWORD\"]"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def get_db_connection():\n",
					"    \"\"\"Create a connection to the PostgreSQL database\"\"\"\n",
					"    try:\n",
					"        conn = psycopg2.connect(\n",
					"            host=DB_HOST,\n",
					"            database=DB_NAME,\n",
					"            user=DB_USER,\n",
					"            password=DB_PASSWORD\n",
					"        )\n",
					"        conn.autocommit = False  # We'll manage transactions ourselves\n",
					"        return conn\n",
					"    except Exception as e:\n",
					"        logging.error(f\"Database connection error: {str(e)}\")\n",
					"        raise"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def get_catchment_areas(req: func.HttpRequest) -> func.HttpResponse:\n",
					"    \"\"\"HTTP trigger function to get catchment area data from PostgreSQL\"\"\"\n",
					"    logging.info('Python HTTP trigger function processed a request for catchment areas')\n",
					"    \n",
					"    try:\n",
					"        conn = get_db_connection()\n",
					"        cursor = conn.cursor()\n",
					"        \n",
					"        # Query to get catchment areas\n",
					"        query = \"\"\"\n",
					"        SELECT loc_code, postcode_start \n",
					"        FROM juror_mod.court_catchment_area\n",
					"        \"\"\"\n",
					"        \n",
					"        cursor.execute(query)\n",
					"        results = cursor.fetchall()\n",
					"        \n",
					"        # Convert results to list of dictionaries\n",
					"        catchment_areas = [{\"loc_code\": loc_code, \"postcode_start\": postcode_start} \n",
					"                         for loc_code, postcode_start in results]\n",
					"        \n",
					"        cursor.close()\n",
					"        conn.close()\n",
					"        \n",
					"        return func.HttpResponse(\n",
					"            json.dumps(catchment_areas),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=200\n",
					"        )\n",
					"    except Exception as e:\n",
					"        logging.error(f\"Error getting catchment areas: {str(e)}\")\n",
					"        return func.HttpResponse(\n",
					"            json.dumps({\"error\": str(e)}),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=500\n",
					"        )\n",
					"\n",
					"\n",
					"def check_existing_records(req: func.HttpRequest) -> func.HttpResponse:\n",
					"    \"\"\"HTTP trigger function to check for existing records by hash_id\"\"\"\n",
					"    logging.info('Python HTTP trigger function processed a request to check existing records')\n",
					"    \n",
					"    try:\n",
					"        # Get hash IDs from request body\n",
					"        req_body = req.get_json()\n",
					"        hash_ids = req_body.get('hash_ids', [])\n",
					"        \n",
					"        if not hash_ids:\n",
					"            return func.HttpResponse(\n",
					"                json.dumps({\"message\": \"No hash_ids provided\"}),\n",
					"                mimetype=\"application/json\",\n",
					"                status_code=400\n",
					"            )\n",
					"        \n",
					"        conn = get_db_connection()\n",
					"        cursor = conn.cursor()\n",
					"        \n",
					"        # Convert list of hash_ids to tuple for SQL query\n",
					"        hash_ids_tuple = tuple(hash_ids)\n",
					"        \n",
					"        # Special case for a single hash_id\n",
					"        if len(hash_ids) == 1:\n",
					"            query = f\"\"\"\n",
					"            SELECT hash_id, part_no, loc_code \n",
					"            FROM juror_eric.voters_temp\n",
					"            WHERE hash_id = '{hash_ids[0]}'\n",
					"            \"\"\"\n",
					"        else:\n",
					"            query = f\"\"\"\n",
					"            SELECT hash_id, part_no, loc_code \n",
					"            FROM juror_eric.voters_temp\n",
					"            WHERE hash_id IN %s\n",
					"            \"\"\"\n",
					"            \n",
					"        # Execute the query\n",
					"        if len(hash_ids) == 1:\n",
					"            cursor.execute(query)\n",
					"        else:\n",
					"            cursor.execute(query, (hash_ids_tuple,))\n",
					"            \n",
					"        results = cursor.fetchall()\n",
					"        \n",
					"        # Convert results to dictionary with hash_id as key\n",
					"        existing_records = {hash_id: {\"part_no\": part_no, \"loc_code\": loc_code} \n",
					"                         for hash_id, part_no, loc_code in results}\n",
					"        \n",
					"        cursor.close()\n",
					"        conn.close()\n",
					"        \n",
					"        return func.HttpResponse(\n",
					"            json.dumps(existing_records),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=200\n",
					"        )\n",
					"    except Exception as e:\n",
					"        logging.error(f\"Error checking existing records: {str(e)}\")\n",
					"        return func.HttpResponse(\n",
					"            json.dumps({\"error\": str(e)}),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=500\n",
					"        )\n",
					"\n",
					"\n",
					"def insert_voters_data(req: func.HttpRequest) -> func.HttpResponse:\n",
					"    \"\"\"HTTP trigger function to insert voters data into PostgreSQL\"\"\"\n",
					"    logging.info('Python HTTP trigger function processed a request to insert voters data')\n",
					"    \n",
					"    try:\n",
					"        # Get records from request body\n",
					"        req_body = req.get_json()\n",
					"        records = req_body.get('records', [])\n",
					"        table_name = req_body.get('table', 'juror_eric.voters_temp')\n",
					"        \n",
					"        if not records:\n",
					"            return func.HttpResponse(\n",
					"                json.dumps({\"message\": \"No records provided\"}),\n",
					"                mimetype=\"application/json\",\n",
					"                status_code=400\n",
					"            )\n",
					"        \n",
					"        conn = get_db_connection()\n",
					"        cursor = conn.cursor()\n",
					"        \n",
					"        # Get first record to determine columns\n",
					"        first_record = records[0]\n",
					"        columns = list(first_record.keys())\n",
					"        \n",
					"        # Generate placeholders for SQL query\n",
					"        placeholders = \", \".join([\"%s\"] * len(columns))\n",
					"        column_names = \", \".join(columns)\n",
					"        \n",
					"        # SQL query for upsert (insert or update)\n",
					"        query = f\"\"\"\n",
					"        INSERT INTO {table_name} ({column_names})\n",
					"        VALUES ({placeholders})\n",
					"        ON CONFLICT (hash_id)  \n",
					"        DO UPDATE SET \n",
					"        {\", \".join([f\"{col} = EXCLUDED.{col}\" for col in columns if col != 'hash_id'])}\n",
					"        \"\"\"\n",
					"        \n",
					"        # Extract values from records\n",
					"        values = [[record.get(col) for col in columns] for record in records]\n",
					"        \n",
					"        # Execute batch insert\n",
					"        execute_batch(cursor, query, values, page_size=1000)\n",
					"        \n",
					"        # Commit the transaction\n",
					"        conn.commit()\n",
					"        \n",
					"        affected_rows = len(records)\n",
					"        cursor.close()\n",
					"        conn.close()\n",
					"        \n",
					"        return func.HttpResponse(\n",
					"            json.dumps({\"message\": f\"Successfully inserted/updated {affected_rows} records\"}),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=200\n",
					"        )\n",
					"    except Exception as e:\n",
					"        logging.error(f\"Error inserting voters data: {str(e)}\")\n",
					"        return func.HttpResponse(\n",
					"            json.dumps({\"error\": str(e)}),\n",
					"            mimetype=\"application/json\",\n",
					"            status_code=500\n",
					"        )"
				],
				"execution_count": null
			}
		]
	}
}